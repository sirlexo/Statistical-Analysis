---
title: "Research"
output: html_document
date: "2024-03-26"
---


```{r}
#Loading Required Library
library(ggplot2)
library(dplyr)
library(corrplot)
library(pwr2)

```

```{r}
#Loading Provided Dataset 
CW = read.csv('Coursework.csv', stringsAsFactors = T)
summary(CW)
```
# Breakdown of Dataset
BatchID is simply a label identifying a specific batch of classification problems.
AI average % classification accuracy of the AI system on each batch of problems.
HE average % classification accuracy of human experts on each batch of problems.
Complexity is a category representing the typical complexity of the classification tasks within each
 batch of problems, with possible values {Simple, Moderate, Difficult}.
Explain is a category representing two possible values of a setting with which the AI system can be
 run. On indicates that the AI runs with additional processing to provide an explanation of
 the predictions within that batch, and Off indicates that additional processing was not run.
Type is a category representing whether the classification problems in a batch were to detect
 either Positive or Negative outcomes.
Each batch consists of a set of classification problems of a given Type and Complexity and with the AI system
set with the Explain setting always On or Off.
```{r}
View(CW) #view the dataset 
str(CW) 
```
```{r}
dim(CW) #show number of rows and columns 

```
```{r}
head(CW) #display first row of data
```
```{r}
names(CW) #display names of column 
```
```{r}
# Statistical summary of individual variables/columns
summary(CW)
```
```{r}
#If the column is numerical we get a  summary ( sd, median, mean, max)
R1 = apply(CW[c(2, 3)], 2, FUN = mean)
R2 = apply(CW[c(2, 3)], 2, FUN = median)
R3 = apply(CW[c(2, 3)], 2, FUN = sd)
R4 = apply(CW[c(2, 3)], 2, FUN = max)
Table1 = rbind(Mean = R1, Median = R2, SD= R3, Max = R4)
Table1
```


From a table we can obtain the proportions in each level. These statistics on the accuracy provide insights into the central tendency (mean and median), spread (standard deviation), and range (maximum) of the data for each variable. We you can infer that the 'AI' variable has a higher mean and maximum value compared to the 'HE' variable, while the 'HE' variable has a slightly higher median and standard deviation compared to the 'AI' variable.

```{r}
#From a table we can obtain the proportions in each level
t1 = table(CW$Complexity)
t1
```
```{r}
t2 = table(CW$Explain)
t2
```
```{r}
t3 = table(CW$Type)
t3
```


```{r}
prop.table(t1)
```
```{r}
prop.table(t2)
```
```{r}
prop.table(t3)
```


```{r}
#And hence we can obtain cumulative counts or proportions
cumsum(t1)
```
```{r}
cbind(Count = t1, Percentage = 100*round(prop.table(t1),3),
      Cumulative = cumsum(t1), CumulativeProp = cumsum(prop.table(t1)))
```
## Visualisations for Categorical Variables

```{r}
# Visualisation for Categorical Variables

# Pie chart using the pie() function


pie(t1, main = 'Pie chart of Complexity',
    col = c('red', 'blue', 'green'))

pie(t2, main = 'Pie chart of Explain',
    col = c('red', 'blue'))
pie(t3, main = 'Pie chart of Type',
    col = c('red', 'green'))
```
```{r}
ggplot(data = CW, aes(x = Complexity, fill = Complexity)) + geom_bar(color = 'black')

ggplot(data = CW, aes(x = Explain, fill = Explain)) + geom_bar(color = 'black')

ggplot(data = CW, aes(x = Type, fill = Type)) + geom_bar(color = 'black')


```
## Cross-tabulation can be done by table function


```{r}
# cross-tabulation can be done by table function
table(CW$Complexity, CW$Type)
table(CW$Complexity, CW$Explain)
table(CW$Explain, CW$Type)
```
## Visualising Dependence of Two Categories
```{r}


# A grouped bar plot has a main variable, the secondary variable specified as the fill, and position set to 'dodge'
ggplot(data = CW, aes(x = Explain, fill = Complexity)) + geom_bar(position = "dodge")
ggplot(data = CW, aes(x = Complexity, fill = Type)) + geom_bar(position = "dodge")
ggplot(data = CW, aes(x = Type, fill = Explain)) + geom_bar(position = "dodge")

```
```{r}
# boxplots of HE broken down by Complexity category
ggplot(data = CW, aes(y = HE, x = Complexity, fill = Complexity)) + geom_boxplot()
```
```{r}
ggplot(data = CW, aes(y = HE, x = Explain, fill = Explain)) + geom_boxplot()
```

```{r}
ggplot(data = CW, aes(y = AI, x = Complexity, fill = Complexity)) + geom_boxplot()
```

```{r}
# boxplots of AI broken down by Explain category
ggplot(data = CW, aes(y = AI, x = Explain, fill = Explain)) + geom_boxplot()
```
```{r}
ggplot(data = CW, aes(y = AI, x = Type, fill = Type)) + geom_boxplot()
```
```{r}
ggplot(data = CW, aes(y = HE, x = Type, fill = Type)) + geom_boxplot()
```


```{r}
# Exploring Dependence between Numerical Variables

# Scatter Plots
ggplot(data = CW, aes(x = HE, y = AI, color = Complexity)) + geom_point()
```
```{r}
ggplot(data = CW, aes(x = HE, y = AI, color = Complexity)) + geom_point() + geom_smooth()
```
```{r}
ggplot(data = CW, aes(x = HE, color = Complexity)) +    
  geom_density()
```
Show a normal distribution for all complexity catergory againt the Human Experts with simple being the highest

```{r}
ggplot(data = CW, aes(x = AI, color = Complexity)) +    
  geom_density()
```
Show a normal distribution for all complexity catergory againt the Human AI with Moderate being the highest

```{r}

#Summarizing nummerical column by complexity category
summarize(CW, mean = mean(HE),
 median = median(HE), .by = Complexity)

summarize(CW, mean = mean(AI),
 median = median(AI), .by = Complexity)
```


Statistics and visualisations seem to suggest some variation in means between the groups

## Anova test

ANOVA Procedure
• Define our Hypothesis:
• H0
: null hypothesis: All group means are the same µ1 = µ2 = µ3
• H1
: alternative hypothesis: At least 2 of the group means are different.

Applying the one-way ANOVA test

Now the one-way ANOVA test can be applied
```{r}
anovaHE = aov(HE ~ Complexity, data = CW)
summary(anovaHE)
```
The one observed, under the null hypothesis that there is no significant difference between the groups defined by 'Complexity'. In this case, it's 0.00823, which is less than the conventional significance level of 0.05.
p < 0.05 (0.00823) so we can reject the null hypothesis enough evidence to say that Complexity affects the Human Expert (HE).
Overall, the output suggests that the 'Complexity' variable has a statistically significant effect on the dependent variable HE, based on the ANOVA test conducted.

```{r}
anovaAI = aov(AI ~ Complexity, data = CW)
summary(anovaAI)
```
It indicates the probability of observing an F-statistic as extreme as, or more extreme than, the one observed, under the null hypothesis that there is no significant difference between the groups defined by 'Complexity'. In this case, it's 0.0447, which is less than the conventional significance level of 0.05.
p < 0.05 (0.0447) so we can reject the null hypothesis enough evidence to say that Complexity affects the AI.
Overall, the output suggests that there is a statistically significant effect of the 'Complexity' variable on the dependent variable AI, based on the ANOVA test conducted.
```{r}
CW$residuals = anovaHE$residuals
ggplot(CW, aes(sample = residuals)) +
 stat_qq(size=2) + stat_qq_line( col = 'red')
```
The points are close to the theoretical line. It is reasonable to assume the distribution is normal.


```{r}
CW$residuals = anovaAI$residuals
ggplot(CW, aes(sample = residuals)) +
 stat_qq(size=2) + stat_qq_line( col = 'red')
```
The points are close to the theoretical line. It is reasonable to assume the distribution is normal.

## Shapiro-Wilk test of normality
```{r}
## Normality test for HE
shapiro.test(anovaHE$residuals)
```
Since the p-value (0.4626) is greater than the significance level (0.05), we fail to reject the null hypothesis.
Therefore, we do not have sufficient evidence to conclude that the residuals significantly deviate from a normal distribution.
This suggests that the assumption of normality for the residuals in the ANOVA analysis is met, indicating that the model's residuals follow a normal distribution.


```{r}
## Normality test for AI
shapiro.test(anovaAI$residuals)
```
The p-value (0.4456) is greater than the significance level (0.05), we fail to reject the null hypothesis.
Therefore, we do not have sufficient evidence to conclude that the residuals significantly deviate from a normal distribution.
This suggests that the assumption of normality for the residuals in the ANOVA analysis is met, indicating that the model's residuals follow a normal distribution.

Both normality checks suggest it is reasonable to assume residuals are normally distributed.
Hence in this case the ANOVA test is VALID

## Kruskal-Wallis rank sum test
```{r}
kruskal.test(AI ~ HE, data = CW)
```
Since the p-value (0.2891) is greater than the significance level (such as 0.05), we fail to reject the null hypothesis.
Therefore, there is insufficient evidence to conclude that there are significant differences in medians between the groups.
In other words, based on this test, there is no statistically significant difference in the 'AI' variable across the different levels of the 'HE' variable.

```{r}
kruskal.test(HE ~ Complexity, data = CW)
```
p < 0.05 (0.02227) so REJECT the null hypothesis.
The Kruskal-Wallis test indicates that there are statistically significant differences in the medians of the 'HE' variable across different levels of the 'Complexity' variable.

```{r}
kruskal.test(HE ~ Type, data = CW)
```
Since the p-value (0.5962) exceeds the significance level (such as 0.05), we do not reject the null hypothesis.
Hence, there is inadequate evidence to conclude that there are significant differences in medians between the groups defined by the 'HE' variable across different levels of 'Type'.
According to the Kruskal-Wallis test results, there are no statistically significant differences in the medians of the 'HE' variable across different levels of the 'Type' variable.

```{r}
kruskal.test(AI ~ Explain, data = CW)
```
Since the p-value (0.009282) is less than the significance level (such as 0.05), we reject the null hypothesis.
Therefore, we have sufficient evidence to conclude that there are significant differences in medians between the groups defined by the 'AI' variable across different levels of 'Explain'.
In other words, the 'Explain' variable significantly affects the 'AI' variable.
In summary, the Kruskal-Wallis test indicates that there are statistically significant differences in the medians of the 'AI' variable across different levels of the 'Explain' variable.

```{r}
kruskal.test(AI ~ Type, data = CW)
```
The p-value (0.1615) is greater than the significance level (such as 0.05), we do not reject the null hypothesis. There is insufficient evidence to conclude that there are significant differences in medians between the groups defined by the 'AI' variable across different levels of 'Type'. In other words, the 'Type' variable does not significantly influence the 'AI' variable.
In summary, according to the Kruskal-Wallis test results, there are no statistically significant differences in the medians of the 'AI' variable across different levels of the 'Type' variable.
```{r}
kruskal.test(AI ~ Complexity, data = CW)
```
The p-value (0.06503) is slightly greater than the significance level (such as 0.05), we do not have strong evidence to reject the null hypothesis.
Therefore, there is not enough evidence to conclude that there are significant differences in medians between the groups defined by the 'AI' variable across different levels of 'Complexity'.
However, it is worth noting that the p-value is close to the significance level, suggesting a marginal level of significance. In summary, according to the Kruskal-Wallis test results, there may not be statistically significant differences in the medians of the 'AI' variable across different levels of the 'Complexity' variable, although the result is borderline and may warrant further investigation.



## Two way Anova
```{r}
round(tapply(CW$AI, list(CW$Complexity, CW$Explain), FUN = mean),2)
round(tapply(CW$HE, list(CW$Complexity, CW$Type), FUN = mean),2)
```
```{r}
anova2HE = aov(HE ~ Complexity + Type, data = CW)
summary(anova2HE)
```
For Complexity, the p-value is 0.00879, which is less than the conventional significance level of 0.05, indicating significance.
For Type, the p-value is 0.53583, which is greater than 0.05, indicating non-significance.
In summary, the ANOVA test suggests that Complexity has a significant effect on the dependent variable HE, while Type does not.
```{r}
anova2AI = aov(AI ~ Complexity + Explain, data = CW)
summary(anova2AI)
```
For Complexity, the p-value is 0.0379, which is less than the conventional significance level of 0.05, indicating significance.
For Explain, the p-value is 0.0591, which is close to 0.05 but still greater, suggesting marginal significance.
The ANOVA test suggests that Complexity has a significant effect on the dependent variable AI, while Explain has a marginally significant effect.
```{r}
CW$residualHE = anova2HE$residuals
ggplot(CW, aes(sample = residualHE)) +
 stat_qq(size=2) + stat_qq_line( col = 'red')

```

```{r}
shapiro.test(anova2HE$residuals)
```
Since the p-value (0.5217) is greater than the common significance level of 0.05, we fail to reject the null hypothesis.
Therefore, there is not enough evidence to conclude that the residuals significantly deviate from a normal distribution.
In other words, based on this test, we can assume that the residuals are approximately normally distributed.
In summary, the Shapiro-Wilk normality test suggests that there is no significant departure from normality in the residuals of the statistical analysis. Hence, assumptions related to the normality of residuals in the underlying statistical model may be considered adequately met.


```{r}
CW$residualAI = anova2AI$residuals
ggplot(CW, aes(sample = residualAI)) +
 stat_qq(size=2) + stat_qq_line( col = 'red')
```
```{r}
shapiro.test(anova2AI$residuals)
```
The p-value (0.9916) is much greater than the significance level of 0.05, we fail to reject the null hypothesis.
Therefore, there is insufficient evidence to conclude that the residuals significantly deviate from a normal distribution.Based on this test, we can assume that the residuals are approximately normally distributed.
In summary, the Shapiro-Wilk normality test suggests that there is no significant departure from normality in the residuals of the statistical analysis. Hence, assumptions related to the normality of residuals in the underlying statistical model may be considered adequately met.




The p-value is > 0.05 so it is reasonable to assume normality.


```{r}
H = TukeyHSD(anova2HE, which = "Complexity")
H
plot(H)
```
It can be seen from the output, that all pairwise comparisons are significant as the intervals contain zero
In summary, according to the Tukey's multiple comparisons test, there is a significant difference in means between Simple and Difficult groups, but no significant differences between Moderate and Difficult, or between Simple and Moderate.

```{r}
H2 = TukeyHSD(anova2AI, which = "Complexity")
H2
plot(H2)
```
It can be seen from the output, that all pairwise comparisons are significant as the intervals contain zero
In summary, according to Tukey's multiple comparisons test, there is a significant difference in means between the 'Simple' and 'Difficult' groups, but no significant differences between the 'Moderate' and 'Difficult', or between the 'Simple' and 'Moderate' groups


## Chi Squared Test

```{r}
resultsCE= chisq.test(CW$Complexity, CW$Explain)
resultsCE
```
Since the p-value (0.007902) is less than 0.05, we reject the null hypothesis. There is sufficient evidence to conclude that there is a statistically significant association between the 'Complexity' and 'Explain' variables in the dataset.
In other words, the variables 'Complexity' and 'Explain' are not independent of each other.
In summary, based on Pearson's Chi-squared test, there is a statistically significant association between the 'Complexity' and 'Explain' variables in the dataset.
```{r}
resultsCE$observed
round(resultsCE$expected,0)
round(resultsCE$residuals,2)
```
```{r}
resultsCT= chisq.test(CW$Complexity, CW$Type)
resultsCT
```
There is insufficient evidence to conclude that there is a statistically significant association between the 'Complexity' and 'Type' variables in the dataset.
In other words, the variables 'Complexity' and 'Type' appear to be independent of each other.
In summary, based on Pearson's Chi-squared test, there is no statistically significant association between the 'Complexity' and 'Type' variables in the dataset.
```{r}
resultsCT$observed
```
```{r}
round(resultsCT$expected,0)
round(resultsCT$residuals,2)
```



```{r}
resultsET= chisq.test(CW$Explain, CW$Type)
resultsET
```
There is no evidence to suggest that there is a statistically significant association between the 'Explain' and 'Type' variables in the dataset.
In other words, the variables 'Explain' and 'Type' appear to be independent of each other.
```{r}
resultsET$observed
round(resultsET$expected,0)
round(resultsET$residuals,2)
```


```{r}
power.t.test(power = 0.99,delta = 2,sd = 3.2,sig.level = 0.01,
type = "two.sample", alternative = "two.sided")

```
```{r}
test = power.t.test(power = 0.99,delta = 2,sd = 3.2,sig.level = 0.01,
type = "two.sample", alternative = "two.sided")
ceiling(test$n)
```
## Wilcoxon signed rank test with continuity correction
```{r}
wilcox.test(CW$HE, y = NULL,
 alternative = "two.sided",
 mu = 400, paired = FALSE, exact = F, correct = T,
 conf.int = F, conf.level = 0.95)
```
```{r}
wilcox.test(CW$AI, y = NULL,
 alternative = "two.sided",
 mu = 400, paired = FALSE, exact = F, correct = T,
 conf.int = F, conf.level = 0.95)
```
```{r}
wilcox.test(CW$AI, y = CW$HE,
 alternative = "two.sided",
 mu = 400, paired = FALSE, exact = F, correct = T,
 conf.int = F, conf.level = 0.95)
```










































